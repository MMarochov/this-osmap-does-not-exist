{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Author: Elisha Paine"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bpWK8oIfagX8",
        "outputId": "43e76fe6-58d2-429c-ce66-4c1ef809cde3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'stylegan3'...\n",
            "remote: Enumerating objects: 207, done.\u001b[K\n",
            "remote: Total 207 (delta 0), reused 0 (delta 0), pack-reused 207\u001b[K\n",
            "Receiving objects: 100% (207/207), 4.17 MiB | 3.11 MiB/s, done.\n",
            "Resolving deltas: 100% (99/99), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/NVlabs/stylegan3.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6nmWbPQrUv5e"
      },
      "outputs": [],
      "source": [
        "# fix an issue with the stylegan3 repo\n",
        "file = \"stylegan3/torch_utils/ops/grid_sample_gradfix.py\"\n",
        "with open(file) as f:\n",
        "  lines = f.read().split(\"\\n\")\n",
        "lines[59] = \"        op, _ = torch._C._jit_get_operation('aten::grid_sampler_2d_backward')\"\n",
        "with open(file, \"w\") as f:\n",
        "  f.write(\"\\n\".join(lines))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H-FRMfu_jKmM",
        "outputId": "5dc5732b-0b7e-4359-d861-ad6e4c0b9842"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting ninja\n",
            "  Downloading ninja-1.10.2.3-py2.py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.whl (108 kB)\n",
            "\u001b[K     |████████████████████████████████| 108 kB 37.3 MB/s \n",
            "\u001b[?25hInstalling collected packages: ninja\n",
            "Successfully installed ninja-1.10.2.3\n",
            "Found existing installation: jax 0.3.14\n",
            "Uninstalling jax-0.3.14:\n",
            "  Successfully uninstalled jax-0.3.14\n",
            "Found existing installation: jaxlib 0.3.14+cuda11.cudnn805\n",
            "Uninstalling jaxlib-0.3.14+cuda11.cudnn805:\n",
            "  Successfully uninstalled jaxlib-0.3.14+cuda11.cudnn805\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Looking in links: https://storage.googleapis.com/jax-releases/jax_cuda_releases.html\n",
            "Collecting jax[cuda11_cudnn805]==0.3.10\n",
            "  Downloading jax-0.3.10.tar.gz (939 kB)\n",
            "\u001b[K     |████████████████████████████████| 939 kB 29.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: absl-py in /usr/local/lib/python3.7/dist-packages (from jax[cuda11_cudnn805]==0.3.10) (1.2.0)\n",
            "Requirement already satisfied: numpy>=1.19 in /usr/local/lib/python3.7/dist-packages (from jax[cuda11_cudnn805]==0.3.10) (1.21.6)\n",
            "Requirement already satisfied: opt_einsum in /usr/local/lib/python3.7/dist-packages (from jax[cuda11_cudnn805]==0.3.10) (3.3.0)\n",
            "Requirement already satisfied: scipy>=1.2.1 in /usr/local/lib/python3.7/dist-packages (from jax[cuda11_cudnn805]==0.3.10) (1.7.3)\n",
            "Requirement already satisfied: typing_extensions in /usr/local/lib/python3.7/dist-packages (from jax[cuda11_cudnn805]==0.3.10) (4.1.1)\n",
            "Collecting jaxlib==0.3.10+cuda11.cudnn805\n",
            "  Downloading https://storage.googleapis.com/jax-releases/cuda11/jaxlib-0.3.10%2Bcuda11.cudnn805-cp37-none-manylinux2014_x86_64.whl (175.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 175.7 MB 7.8 kB/s \n",
            "\u001b[?25hRequirement already satisfied: flatbuffers<3.0,>=1.12 in /usr/local/lib/python3.7/dist-packages (from jaxlib==0.3.10+cuda11.cudnn805->jax[cuda11_cudnn805]==0.3.10) (2.0)\n",
            "Building wheels for collected packages: jax\n",
            "  Building wheel for jax (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for jax: filename=jax-0.3.10-py3-none-any.whl size=1088066 sha256=d4ddf0686b762a76b6e81b879cc6d32398ea2368e7ea0fb9c50c700020614735\n",
            "  Stored in directory: /root/.cache/pip/wheels/1c/05/23/36730377cd7311156f1e5eb5e7c683d5cdac1654658c095cc5\n",
            "Successfully built jax\n",
            "Installing collected packages: jaxlib, jax\n",
            "Successfully installed jax-0.3.10 jaxlib-0.3.10+cuda11.cudnn805\n"
          ]
        }
      ],
      "source": [
        "!pip install ninja\n",
        "!pip uninstall jax jaxlib -y\n",
        "!pip install \"jax[cuda11_cudnn805]==0.3.10\" -f https://storage.googleapis.com/jax-releases/jax_cuda_releases.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MyDHwF0tIwcK",
        "outputId": "d5d47d87-31d2-4c74-a7bb-abe0ba75f611"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at drive; to attempt to forcibly remount, call drive.mount(\"drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-sAGzpu-ajhT",
        "outputId": "24bd2647-a72e-4c49-8d48-bd1d6aa8c02a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Training options:\n",
            "{\n",
            "  \"G_kwargs\": {\n",
            "    \"class_name\": \"training.networks_stylegan3.Generator\",\n",
            "    \"z_dim\": 512,\n",
            "    \"w_dim\": 512,\n",
            "    \"mapping_kwargs\": {\n",
            "      \"num_layers\": 2\n",
            "    },\n",
            "    \"channel_base\": 32768,\n",
            "    \"channel_max\": 512,\n",
            "    \"magnitude_ema_beta\": 0.9994456359721023\n",
            "  },\n",
            "  \"D_kwargs\": {\n",
            "    \"class_name\": \"training.networks_stylegan2.Discriminator\",\n",
            "    \"block_kwargs\": {\n",
            "      \"freeze_layers\": 0\n",
            "    },\n",
            "    \"mapping_kwargs\": {},\n",
            "    \"epilogue_kwargs\": {\n",
            "      \"mbstd_group_size\": 4\n",
            "    },\n",
            "    \"channel_base\": 32768,\n",
            "    \"channel_max\": 512\n",
            "  },\n",
            "  \"G_opt_kwargs\": {\n",
            "    \"class_name\": \"torch.optim.Adam\",\n",
            "    \"betas\": [\n",
            "      0,\n",
            "      0.99\n",
            "    ],\n",
            "    \"eps\": 1e-08,\n",
            "    \"lr\": 0.0025\n",
            "  },\n",
            "  \"D_opt_kwargs\": {\n",
            "    \"class_name\": \"torch.optim.Adam\",\n",
            "    \"betas\": [\n",
            "      0,\n",
            "      0.99\n",
            "    ],\n",
            "    \"eps\": 1e-08,\n",
            "    \"lr\": 0.002\n",
            "  },\n",
            "  \"loss_kwargs\": {\n",
            "    \"class_name\": \"training.loss.StyleGAN2Loss\",\n",
            "    \"r1_gamma\": 8.0\n",
            "  },\n",
            "  \"data_loader_kwargs\": {\n",
            "    \"pin_memory\": true,\n",
            "    \"prefetch_factor\": 2,\n",
            "    \"num_workers\": 3\n",
            "  },\n",
            "  \"training_set_kwargs\": {\n",
            "    \"class_name\": \"training.dataset.ImageFolderDataset\",\n",
            "    \"path\": \"drive/MyDrive/Colab Notebooks/os_tiles_256\",\n",
            "    \"use_labels\": false,\n",
            "    \"max_size\": 1510,\n",
            "    \"xflip\": false,\n",
            "    \"resolution\": 256,\n",
            "    \"random_seed\": 0\n",
            "  },\n",
            "  \"num_gpus\": 1,\n",
            "  \"batch_size\": 16,\n",
            "  \"batch_gpu\": 16,\n",
            "  \"metrics\": [\n",
            "    \"fid50k_full\"\n",
            "  ],\n",
            "  \"total_kimg\": 25000,\n",
            "  \"kimg_per_tick\": 4,\n",
            "  \"image_snapshot_ticks\": 50,\n",
            "  \"network_snapshot_ticks\": 50,\n",
            "  \"random_seed\": 0,\n",
            "  \"ema_kimg\": 5.0,\n",
            "  \"augment_kwargs\": {\n",
            "    \"class_name\": \"training.augment.AugmentPipe\",\n",
            "    \"xflip\": 1,\n",
            "    \"rotate90\": 1,\n",
            "    \"xint\": 1,\n",
            "    \"scale\": 1,\n",
            "    \"rotate\": 1,\n",
            "    \"aniso\": 1,\n",
            "    \"xfrac\": 1,\n",
            "    \"brightness\": 1,\n",
            "    \"contrast\": 1,\n",
            "    \"lumaflip\": 1,\n",
            "    \"hue\": 1,\n",
            "    \"saturation\": 1\n",
            "  },\n",
            "  \"ada_target\": 0.6,\n",
            "  \"run_dir\": \"weights/00005-stylegan3-t-os_tiles_256-gpus1-batch16-gamma8\"\n",
            "}\n",
            "\n",
            "Output directory:    weights/00005-stylegan3-t-os_tiles_256-gpus1-batch16-gamma8\n",
            "Number of GPUs:      1\n",
            "Batch size:          16 images\n",
            "Training duration:   25000 kimg\n",
            "Dataset path:        drive/MyDrive/Colab Notebooks/os_tiles_256\n",
            "Dataset size:        1510 images\n",
            "Dataset resolution:  256\n",
            "Dataset labels:      False\n",
            "Dataset x-flips:     False\n",
            "\n",
            "Creating output directory...\n",
            "Launching processes...\n",
            "Loading training set...\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 3 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "Num images:  1510\n",
            "Image shape: [3, 256, 256]\n",
            "Label shape: [0]\n",
            "\n",
            "Constructing networks...\n",
            "Setting up PyTorch plugin \"bias_act_plugin\"... Done.\n",
            "Setting up PyTorch plugin \"filtered_lrelu_plugin\"... Done.\n",
            "\n",
            "Generator                     Parameters  Buffers  Output shape         Datatype\n",
            "---                           ---         ---      ---                  ---     \n",
            "mapping.fc0                   262656      -        [16, 512]            float32 \n",
            "mapping.fc1                   262656      -        [16, 512]            float32 \n",
            "mapping                       -           512      [16, 16, 512]        float32 \n",
            "synthesis.input.affine        2052        -        [16, 4]              float32 \n",
            "synthesis.input               262144      1545     [16, 512, 36, 36]    float32 \n",
            "synthesis.L0_36_512.affine    262656      -        [16, 512]            float32 \n",
            "synthesis.L0_36_512           2359808     25       [16, 512, 36, 36]    float32 \n",
            "synthesis.L1_36_512.affine    262656      -        [16, 512]            float32 \n",
            "synthesis.L1_36_512           2359808     25       [16, 512, 36, 36]    float32 \n",
            "synthesis.L2_36_512.affine    262656      -        [16, 512]            float32 \n",
            "synthesis.L2_36_512           2359808     25       [16, 512, 36, 36]    float32 \n",
            "synthesis.L3_52_512.affine    262656      -        [16, 512]            float32 \n",
            "synthesis.L3_52_512           2359808     37       [16, 512, 52, 52]    float16 \n",
            "synthesis.L4_52_512.affine    262656      -        [16, 512]            float32 \n",
            "synthesis.L4_52_512           2359808     25       [16, 512, 52, 52]    float16 \n",
            "synthesis.L5_84_512.affine    262656      -        [16, 512]            float32 \n",
            "synthesis.L5_84_512           2359808     37       [16, 512, 84, 84]    float16 \n",
            "synthesis.L6_84_512.affine    262656      -        [16, 512]            float32 \n",
            "synthesis.L6_84_512           2359808     25       [16, 512, 84, 84]    float16 \n",
            "synthesis.L7_148_512.affine   262656      -        [16, 512]            float32 \n",
            "synthesis.L7_148_512          2359808     37       [16, 512, 148, 148]  float16 \n",
            "synthesis.L8_148_512.affine   262656      -        [16, 512]            float32 \n",
            "synthesis.L8_148_512          2359808     25       [16, 512, 148, 148]  float16 \n",
            "synthesis.L9_148_362.affine   262656      -        [16, 512]            float32 \n",
            "synthesis.L9_148_362          1668458     25       [16, 362, 148, 148]  float16 \n",
            "synthesis.L10_276_256.affine  185706      -        [16, 362]            float32 \n",
            "synthesis.L10_276_256         834304      37       [16, 256, 276, 276]  float16 \n",
            "synthesis.L11_276_181.affine  131328      -        [16, 256]            float32 \n",
            "synthesis.L11_276_181         417205      25       [16, 181, 276, 276]  float16 \n",
            "synthesis.L12_276_128.affine  92853       -        [16, 181]            float32 \n",
            "synthesis.L12_276_128         208640      25       [16, 128, 276, 276]  float16 \n",
            "synthesis.L13_256_128.affine  65664       -        [16, 128]            float32 \n",
            "synthesis.L13_256_128         147584      25       [16, 128, 256, 256]  float16 \n",
            "synthesis.L14_256_3.affine    65664       -        [16, 128]            float32 \n",
            "synthesis.L14_256_3           387         1        [16, 3, 256, 256]    float16 \n",
            "synthesis                     -           -        [16, 3, 256, 256]    float32 \n",
            "---                           ---         ---      ---                  ---     \n",
            "Total                         28472133    2456     -                    -       \n",
            "\n",
            "Setting up PyTorch plugin \"upfirdn2d_plugin\"... Done.\n",
            "\n",
            "Discriminator  Parameters  Buffers  Output shape         Datatype\n",
            "---            ---         ---      ---                  ---     \n",
            "b256.fromrgb   512         16       [16, 128, 256, 256]  float16 \n",
            "b256.skip      32768       16       [16, 256, 128, 128]  float16 \n",
            "b256.conv0     147584      16       [16, 128, 256, 256]  float16 \n",
            "b256.conv1     295168      16       [16, 256, 128, 128]  float16 \n",
            "b256           -           16       [16, 256, 128, 128]  float16 \n",
            "b128.skip      131072      16       [16, 512, 64, 64]    float16 \n",
            "b128.conv0     590080      16       [16, 256, 128, 128]  float16 \n",
            "b128.conv1     1180160     16       [16, 512, 64, 64]    float16 \n",
            "b128           -           16       [16, 512, 64, 64]    float16 \n",
            "b64.skip       262144      16       [16, 512, 32, 32]    float16 \n",
            "b64.conv0      2359808     16       [16, 512, 64, 64]    float16 \n",
            "b64.conv1      2359808     16       [16, 512, 32, 32]    float16 \n",
            "b64            -           16       [16, 512, 32, 32]    float16 \n",
            "b32.skip       262144      16       [16, 512, 16, 16]    float16 \n",
            "b32.conv0      2359808     16       [16, 512, 32, 32]    float16 \n",
            "b32.conv1      2359808     16       [16, 512, 16, 16]    float16 \n",
            "b32            -           16       [16, 512, 16, 16]    float16 \n",
            "b16.skip       262144      16       [16, 512, 8, 8]      float32 \n",
            "b16.conv0      2359808     16       [16, 512, 16, 16]    float32 \n",
            "b16.conv1      2359808     16       [16, 512, 8, 8]      float32 \n",
            "b16            -           16       [16, 512, 8, 8]      float32 \n",
            "b8.skip        262144      16       [16, 512, 4, 4]      float32 \n",
            "b8.conv0       2359808     16       [16, 512, 8, 8]      float32 \n",
            "b8.conv1       2359808     16       [16, 512, 4, 4]      float32 \n",
            "b8             -           16       [16, 512, 4, 4]      float32 \n",
            "b4.mbstd       -           -        [16, 513, 4, 4]      float32 \n",
            "b4.conv        2364416     16       [16, 512, 4, 4]      float32 \n",
            "b4.fc          4194816     -        [16, 512]            float32 \n",
            "b4.out         513         -        [16, 1]              float32 \n",
            "---            ---         ---      ---                  ---     \n",
            "Total          28864129    416      -                    -       \n",
            "\n",
            "Setting up augmentation...\n",
            "Distributing across 1 GPUs...\n",
            "Setting up training phases...\n",
            "Exporting sample images...\n",
            "Initializing logs...\n",
            "Training for 25000 kimg...\n",
            "\n",
            "tick 0     kimg 0.0      time 1m 57s       sec/tick 45.1    sec/kimg 2817.35 maintenance 71.5   cpumem 5.25   gpumem 11.45  reserved 12.79  augment 0.000\n",
            "Evaluating metrics...\n",
            "{\"results\": {\"fid50k_full\": 499.3171184401832}, \"metric\": \"fid50k_full\", \"total_time\": 2817.011412858963, \"total_time_str\": \"46m 57s\", \"num_gpus\": 1, \"snapshot_pkl\": \"network-snapshot-000000.pkl\", \"timestamp\": 1661440736.665462}\n"
          ]
        }
      ],
      "source": [
        "!python stylegan3/train.py --outdir=weights --cfg=stylegan3-t --data=drive/MyDrive/Colab\\ Notebooks/os_tiles_256 --batch=16 --gpus=1 --gamma=8"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "wkBg2e7vh_pW",
        "outputId": "509b2d13-689d-46ef-8ead-61f83ab8095c"
      },
      "outputs": [
        {
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-016931954f47>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"stylegan3\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpersistence\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"weights/00008-stylegan3-t-tiles-gpus1-batch8-gamma8/network-snapshot-000000.pkl\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m   \u001b[0mG\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"G_ema\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mz_dim\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'weights/00008-stylegan3-t-tiles-gpus1-batch8-gamma8/network-snapshot-000000.pkl'"
          ]
        }
      ],
      "source": [
        "import cv2\n",
        "import numpy\n",
        "import pickle\n",
        "import sys\n",
        "import torch\n",
        "sys.path.append(\"stylegan3\")\n",
        "import torch_utils.persistence\n",
        "with open(\"weights/00008-stylegan3-t-tiles-gpus1-batch8-gamma8/network-snapshot-000000.pkl\", \"rb\") as f:\n",
        "  G = pickle.load(f)[\"G_ema\"].cuda()\n",
        "z = torch.randn([1, G.z_dim]).cuda()\n",
        "img = G(z, None)\n",
        "cv_im = img.cpu().numpy()\n",
        "cv_im *= 2 ** 8\n",
        "w, h = cv_im.shape[2:]\n",
        "cv_im = cv_im.squeeze(0).transpose((1, 2, 0)).astype(numpy.uint8, casting=\"unsafe\")\n",
        "cv2.imwrite(\"sample.png\", cv_im);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n3uGHdF56d0A"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
